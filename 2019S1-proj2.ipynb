{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2019 Semester 1\n",
    "-----\n",
    "## Project 2: geotag\n",
    "-----\n",
    "###### Student Name(s):Xiaoxuan Li 933206\n",
    "###### Python version:Python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import classifiers\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "#import evaluate tools\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X, y = [], []\n",
    "#with open('train-raw.tsv') as trainData:\n",
    "    #tsvreader = csv.reader(trainData, delimiter = \"\\t\")\n",
    "    #for line in tsvreader:\n",
    "        #y.append(line[1])\n",
    "        #X.append(line[2])\n",
    "    #y = y[1:]\n",
    "    #X = X[1:]\n",
    "    \n",
    "    #vectoriser = CountVectorizer()\n",
    "    #X = vectoriser.fit_transform(X)\n",
    "    \n",
    "\n",
    "#mi = SelectKBest(score_func=mutual_info_classif, k=1000)\n",
    "#mi.fit(X, y)\n",
    "\n",
    "#for feat_num in mi.get_support(indices=True):\n",
    "    #print(vectoriser.get_feature_names()[feat_num])\n",
    "    \n",
    "#X_mi = mi.transform(X)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should appear knn\n",
    "models = [GaussianNB(),\n",
    "          MultinomialNB(),\n",
    "          DecisionTreeClassifier(max_depth=None, criterion=\"entropy\"),\n",
    "          svm.LinearSVC(),\n",
    "          svm.SVC(kernel='rbf', gamma=0.7, C=1.0),\n",
    "          LogisticRegression(),\n",
    "          DummyClassifier(strategy='most_frequent'),\n",
    "          DecisionTreeClassifier(max_depth=1, criterion=\"entropy\")]\n",
    "titles = ['GNB',\n",
    "          'MNB',\n",
    "          'Decision Tree',\n",
    "          'LinearSVC',\n",
    "          'SVC with rbf kernel',\n",
    "          'Logistic Regression',\n",
    "          'Zero-R'\n",
    "          'One-R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X0, X, y = [], [], []\n",
    "with open('train-top100.csv') as trainData:\n",
    "    tsvreader = csv.reader(trainData, delimiter = \",\")\n",
    "    for line in tsvreader:\n",
    "        y.append(line[-1])\n",
    "        X0.append(line[1:-1])\n",
    "    y = y[1:]\n",
    "    X0 = X0[1:]\n",
    "    \n",
    "    for entry in X0:\n",
    "        X.append(np.array(entry).astype(np.float))\n",
    "    \n",
    "    #vectoriser = CountVectorizer()\n",
    "    #X = vectoriser.fit_transform(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB 0.3348166405674557 time: 26.21943974494934\n",
      "MNB 0.33661609757412075 time: 7.445412874221802\n",
      "Decision Tree 0.33510699304154123 time: 1024.3456909656525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC 0.33798018680647457 time: 517.5005738735199\n"
     ]
    }
   ],
   "source": [
    "for title, model in zip(titles, models):\n",
    "    start = time.time()\n",
    "    model.fit(X, y)\n",
    "    acc = np.mean(cross_val_score(model, X, y, cv=10))\n",
    "    end = time.time()\n",
    "    t = end - start\n",
    "    print(title, acc, 'time:', t)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogisticRegression(),\n",
    "          DummyClassifier(strategy='most_frequent'),\n",
    "          DecisionTreeClassifier(max_depth=1, criterion=\"entropy\")]\n",
    "titles = ['Logistic Regression',\n",
    "          'Zero-R'\n",
    "          'One-R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 0.3370030383373954 time: 29.81513500213623\n",
      "Zero-ROne-R 0.25 time: 1.2296059131622314\n"
     ]
    }
   ],
   "source": [
    "for title, model in zip(titles, models):\n",
    "    start = time.time()\n",
    "    model.fit(X, y)\n",
    "    acc = np.mean(cross_val_score(model, X, y, cv=10))\n",
    "    end = time.time()\n",
    "    t = end - start\n",
    "    print(title, acc, 'time:', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: {'Melbourne', 'Sydney', 'Perth', 'Brisbane'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/valerie/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacker acc: 0.3102422553328331\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "class StackingClassifier():\n",
    "\n",
    "    def __init__(self, classifiers, metaclassifier):\n",
    "        self.classifiers = classifiers\n",
    "        self.metaclassifier = metaclassifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for clf in self.classifiers:\n",
    "            clf.fit(X, y)\n",
    "        X_meta = self._predict_base(X)\n",
    "        self.metaclassifier.fit(X_meta, y)\n",
    "    \n",
    "    def _predict_base(self, X):\n",
    "        yhats = []\n",
    "        for clf in self.classifiers:\n",
    "            yhat = clf.predict_proba(X)\n",
    "            yhats.append(yhat)\n",
    "        yhats = np.concatenate(yhats, axis=1)\n",
    "        #print(yhats.shape)\n",
    "        #assert yhats.shape[0] == X.shape[0]\n",
    "        assert len(yhats) == len(X)\n",
    "        return yhats\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_meta = self._predict_base(X)\n",
    "        yhat = self.metaclassifier.predict(X_meta)\n",
    "        return yhat\n",
    "    def score(self, X, y):\n",
    "        yhat = self.predict(X)\n",
    "        return accuracy_score(y, yhat)\n",
    "    \n",
    "\n",
    "\n",
    "classifiers = [LogisticRegression(),\n",
    "                GaussianNB(),\n",
    "                MultinomialNB(),\n",
    "                DecisionTreeClassifier()]\n",
    "\n",
    "meta_classifier = DecisionTreeClassifier()\n",
    "stacker = StackingClassifier(classifiers, meta_classifier)\n",
    "\n",
    "def load_data(file_name):\n",
    "    X = []\n",
    "    X0 = []\n",
    "    y = []\n",
    "    with open(file_name, mode='r') as fin:\n",
    "        for line in fin:\n",
    "            atts = line.strip().split(\",\")\n",
    "            X0.append(atts[1:-1]) #all atts minus the last one\n",
    "            y.append(atts[-1])\n",
    "    y = y[1:]\n",
    "    X0 = X0[1:]\n",
    "    for entry in X0:\n",
    "        X.append(np.array(entry).astype(np.float))\n",
    "    return X, y\n",
    "\n",
    "X, y = load_data('train-top100.csv')\n",
    "print('labels:', set(y))\n",
    "stacker.fit(X, y)\n",
    "X_test, y_test = load_data('dev-top100.csv')\n",
    "#acc = np.mean(cross_val_score(stacker, X, y, cv=10))\n",
    "print('stacker acc:', stacker.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108148\n",
      "95735\n"
     ]
    }
   ],
   "source": [
    "#generate the final test output\n",
    "X = []\n",
    "X0 = []\n",
    "X1 = []\n",
    "y = []\n",
    "with open(\"test-top100.csv\", mode='r') as fin:\n",
    "    for line in fin:\n",
    "        atts = line.strip().split(\",\")\n",
    "        X0.append(atts[1:-1])\n",
    "        y.append(atts[0])\n",
    "    X0 = X0[1:]\n",
    "    y= y[1:]\n",
    "    for entry in X0:\n",
    "        X1.append(np.array(entry).astype(np.float))\n",
    "        \n",
    "    yhat = stacker.predict(X1)\n",
    "\n",
    "count = 0\n",
    "for entry in yhat:\n",
    "    X.append(entry)\n",
    "    if(entry == \"Brisbane\"):\n",
    "        count = count +1\n",
    "print(len(X))\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_out = open(\"result.csv\",'w')\n",
    "f_out.write(\"Id\")\n",
    "f_out.write(\",\")\n",
    "f_out.write(\"Class\")\n",
    "f_out.write(\"\\n\")\n",
    "for entryid,entry in zip(y, yhat):\n",
    "    f_out.write(entryid)\n",
    "    f_out.write(\",\")\n",
    "    f_out.write(entry)\n",
    "    f_out.write(\"\\n\")\n",
    "\n",
    "f_out.close()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment on dev data set\n",
    "X, y = [], []\n",
    "with open('dev-raw.tsv') as devData:\n",
    "    tsvreader = csv.reader(devData, delimiter = \"\\t\")\n",
    "    for line in tsvreader:\n",
    "        if(len(line)== 3):\n",
    "            y.append(line[1])\n",
    "            X.append(line[2])\n",
    "    \n",
    "    \n",
    "    vectoriser = CountVectorizer()\n",
    "    X = vectoriser.fit_transform(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [GaussianNB(),\n",
    "          MultinomialNB()]\n",
    "          #DecisionTreeClassifier(max_depth=None, criterion=\"entropy\"),\n",
    "          #svm.LinearSVC(),\n",
    "          #LogisticRegression()]\n",
    "titles = ['GNB',\n",
    "          'MNB']\n",
    "          #'Decision Tree',\n",
    "          #'LinearSVC',\n",
    "          #'Logistic Regression']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineer(choose from x2/mi repsentation)\n",
    "k = 10000\n",
    "\n",
    "x2 = SelectKBest(chi2, k=k)\n",
    "x2.fit(X_train,y_train)\n",
    "\n",
    "#for feat_num in x2.get_support(indices=True):\n",
    "    #print(vectoriser.get_feature_names()[feat_num])\n",
    "    \n",
    "X_train_x2 = x2.transform(X_train)\n",
    "X_test_x2 = x2.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "mi = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "mi.fit(X_train,y_train)\n",
    "\n",
    "#for feat_num in mi.get_support(indices=True):\n",
    "    #print(vectoriser.get_feature_names()[feat_num])\n",
    "    \n",
    "X_train_mi = mi.transform(X_train)\n",
    "X_test_mi = mi.transform(X_test)\n",
    "\n",
    "\n",
    "Xs = [(X_train, X_test), (X_train_x2, X_test_x2), (X_train_mi, X_test_mi)]\n",
    "X_names = ['complete', 'x2', 'mi']\n",
    "for title, model in zip(titles, models):\n",
    "    for X_name, X in zip(X_names, Xs):\n",
    "        X_train_t, X_test_t = X\n",
    "        model.fit(X_train_t.todense(), y_train)\n",
    "        acc = model.score(X_test_t.todense(), y_test)\n",
    "        print('k', k, title, 'features', X_name, 'acc',  acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune hyperparams using dev(choose the number of k in kNN)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
